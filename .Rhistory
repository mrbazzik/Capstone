str(train)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
train<-training[,58:69]
train$diagnosis<-training$diagnosis
model1<-train(diagnosis~., data=train, method="glm")
install.packages("e1071")
model1<-train(diagnosis~., data=train, method="glm")
pr1<-predict(model1, train)
test<-testing[,58:69]
test$diagnosis<-testing$diagnosis
pr2<-predict(model1, test)
sum(pr2==test$diagnosis)/len(test$diagnosis)
dim(test[1])
dim(test)
sum(pr2==test$diagnosis)/82
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmantationOriginal)
head(segmentationOriginal)
training<-segmentationOriginal[, Case=="Test"]
training<-segmentationOriginal[, select(Case=="Test")]
training<-subset(segmentationOriginal, Case=="Test")
training<-subset(segmentationOriginal, Case=="Train")
testing<-subset(segmentationOriginal, Case=="Test")
model<-train(Case~., data = segmentationOriginal[,-c("Case")],method="rpart")
model<-train(Case~., data = segmentationOriginal[,-"Case"],method="rpart")
model<-train(Case~., data = segmentationOriginal[,-Case],method="rpart")
model<-train(Case~., data = segmentationOriginal,method="rpart")
Tot<-c(23000, 50000, 57000, NA)
Fiber<-c(10, 10, 8, 8)
Perim<-c(2, NA, NA, 2)
VarIn<-c(NA, 100, 100, 100)
df<- data.frame(TotalIntench2 = Tot, FiberWidthCh1 = Fiber, PerimStatusCh1=Perim, VarIntenCh4=VarIn)
predict(model, df)
model<-train(Class~., data = subset(segmentationOriginal, select = -c("Case")),method="rpart")
model<-train(Class~., data = subset(segmentationOriginal, select = -c(Case)),method="rpart")
Tot<-c(23000, 50000, 57000, NA)
Fiber<-c(10, 10, 8, 8)
Perim<-c(2, NA, NA, 2)
VarIn<-c(NA, 100, 100, 100)
df<- data.frame(TotalIntench2 = Tot, FiberWidthCh1 = Fiber, PerimStatusCh1=Perim, VarIntenCh4=VarIn)
predict(model, df)
names(df)
names(segmentationOriginal)
print(model$finalModel)
plot(model$finalModel)
plot(model$finalModel, uniform=TRUE)
plot(model$finalModel, uniform=TRUE)
text(model$finalModel, all=TRUE)
training<-subset(segmentationOriginal, Case=="Train")
testing<-subset(segmentationOriginal, Case=="Test")
set.seed(125)
model<-train(Class~., data = subset(segmentationOriginal, select = -c(Case)),method="rpart")
set.seed(125)
model<-train(Class~., data = subset(training, select = -c(Case)),method="rpart")
print(model$finalModel)
plot(model$finalModel, uniform=TRUE)
text(model$finalModel, all=TRUE)
library(pgmm)
install.packages("pgmm")
c
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
str(olive)
model<-train(Area~., data = olive,method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
pr<-predict(model, newdata)
pr
unique(olive$Area)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
str(trainSA)
model<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm", family="binomial")
model<-train(factor(chd)~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm", family="binomial")
set.seed(13234)
model<-train(factor(chd)~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm", family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
prtr<-predict(model, training)
prtr<-predict(model, trainSA)
prte<-predict(model, testSA)
missClass(trainSA$chd, prtr)
set.seed(13234)
model<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm", family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
prtr<-predict(model, trainSA)
prte<-predict(model, testSA)
missClass(trainSA$chd, prtr)
missClass(testSA$chd, prte)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
vowel.train$y<-factor(vowel.train$y)
vowel.test$y<-factor(vowel.test$y)
set.seed(33833)
varImp(model)
library(caret)
varImp(model)
set.seed(33833)
model<-train(y~., data=vowel.train, method="rf")
model<-train(y~., data=vowel.train, method="rf")
varImp(model)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
set.seed(33833)
mod1<-train(y~.,data=vowel.train, method="rf")
library(caret)
mod1<-train(y~.,data=vowel.train, method="rf")
mod2<-train(y~., data=vowel.train, method="gbm")
mod2<-train(y~., data=vowel.train, method="gbm")
pr1<-predict(mod1, data=vowel.test)
pr1<-predict(mod1, vowel.test)
pr2<-predict(mod2, vowel.test)
sum(pr1==vowel.test$y)/dim(vowel.test)[1]
pr1
sum(round(pr1)==vowel.test$y)/dim(vowel.test)[1]
pr1<-predict(mod1, vowel.test, type="class")
mod1<-train(y~.,data=vowel.train, method="rf", type="class")
mod2<-train(y~., data=vowel.train, method="gbm", type="class")
pr1<-predict(mod1, vowel.test, type="class")
mod1<-randomForest(y~.,data=vowel.train)
mod2<-gbm(y~.,data=vowel.train)
pr1<-predict(mod1, vowel.test, type="class")
pr2<-predict(mod2, vowel.test, type="class")
sum(pr1==vowel.test$y)/dim(vowel.test)[1]
pr1
sum(round(pr1)==vowel.test$y)/dim(vowel.test)[1]
pr1<-predict(mod1, vowel.test, type="class")
pr2<-predict(mod2, vowel.test, type="class")
names(getModelInfo())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1<-train(diagnosis~., data=training, method="rf")
mod2<-train(diagnosis~., data=training, method="gbm")
mod3<-train(diagnosis~., data=training, method="lda")
pr1<-predict(mod1, testing)
pr1
sum(pr1==testing$diagnosis)/dim(testing)[1]
pr2<-predict(mod2, testing)
sum(pr2==testing$diagnosis)/dim(testing)[1]
pr3<-predict(mod3, testing)
sum(pr3==testing$diagnosis)/dim(testing)[1]
newframe<-data.frame(pr1, pr2, pr3, testing$diagnosis)
summary(newframe)
newframe<-data.frame(pr1, pr2, pr3, diag=testing$diagnosis)
summary(newframe)
mod<-train(diag~., data=newframe, method="rf")
pr<-predict(mod, testing)
sum(pr==newframe$diag)/dim(newframe)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
?plot.enet
?lasso
?relaxo
mod<-train(diagnosis~., data=training, method="enet")
str(training)
mod<-train(CompressiveStrength~., data=training, method="enet")
mod<-train(CompressiveStrength~., data=training, method="enet")
?plot.enet
plot.enet(mod)
?enet
mod<-enet(subset(training, select=-c("CompressiveStrength")),training$CompressiveStrength, lambda=0.1)
mod<-enet(subset(training, select=-c(CompressiveStrength)),training$CompressiveStrength, lambda=0.1)
str(training)
str(subset(training, select=-c(CompressiveStrength)))
?as.matrix
mod<-enet(as.matrix(subset(training, select=-c(CompressiveStrength))),training$CompressiveStrength, lambda=0.1)
plot.enet(mod)
?plot.enet
mod<-enet(as.matrix(subset(training, select=-c(CompressiveStrength))),training$CompressiveStrength, lambda=0.1, xvar="penalty")
mod<-enet(as.matrix(subset(training, select=-c(CompressiveStrength))),training$CompressiveStrength, lambda=0.1)
plot.enet(mod,xvar="penalty")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
install.packages("forecast")
?bats
dat = read.csv("C:/Users/Basov_il/Documents/GitHub/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod<-bats(training)
library(forecast)
bats
?bats
mod<-bats(training)
str(training)
mod<-bats(tstrain)
plot(forecast(mod))
lines(testing$visitsTumblr)
summary(mod)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
install.packages("e1071")
install.packages("e1071")
library(e1071)
?svm
set.seed(325)
str(training)
mod<-train(CompressiveStrength~., data=training, method="svm")
?svm
library("tm")
set.seed(123)
selectRandomData<-function(vec, prop){
selects<-rbinom(length(vec),1,prop)==1
vec[selects]
}
readDocuments<-function(path, prop){
con <- file(path, "r")
docs<-readLines(con)
close(con)
selectRandomData(docs, prop)
}
setwd("c:/Users/Basov_il/Documents/GitHub/Capstone/")
twits<-readDocuments("final/en_US/en_US.twitter.txt", 0.0001)
news<-readDocuments("final/en_US/en_US.news.txt", 0.0001)
blogs<-readDocuments("final/en_US/en_US.blogs.txt", 0.0001)
data<-c(twits, blogs, news)
remove(twits)
remove(blogs)
remove(news)
corps <- VCorpus(VectorSource(data))
remove(data)
badwords <- readLines("badwords.txt")
corps <- tm_map(corps, removePunctuation)
corps <- tm_map(corps, removeNumbers)
corps <- tm_map(corps, removeWords, badwords)
corps <- tm_map(corps, stripWhitespace)
tdm<-TermDocumentMatrix(corps)
dim(tdm)
inspect(tdm[1:50,1:10])
tdmFreq<-removeSparseTerms(tdm, 0.98)
dim(tdmFreq)
inspect(tdmFreq)
findFreqTerms(tdm, 50)
mat<-as.matrix(tdmFreq)
library(reshape2)
mat <- melt(mat, value.name = "count")
head(mat)
library(ggplot2)
ggplot(mat, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("")
corps$terms
summary(corps)
tdmFreq$terms
tdmFreq$Terms
inspect(tdmFreq)
names(tdmFreq)
tdmFreq$dimnames
tdmFreq$dimnames$Terms
assocs<-findAssocs(tdm, tdmFreq$dimnames$Terms, 0)
head(assocs)
names(assocs)
df<-data.frame()
columns(df)
names(df)
names(df)<-tdmFreq$dimnames$Terms
?data.frame
?rbind
a<-c(1,2,3)
names(a)<-"rtt"
a
row.names(a)<-"rtt"
a<-c(c(1),c(2),c(3))
a
row.names(a)<-"rtt"
names(a)<-"rtt"
a
df['and'] = assocs['and']
df
assocs['and']
df['and'] <- assocs['and']
df
values(assocs['and'])
View(df)
df<-data.frame()
df['and'] <- assocs['and']
df<-data.frame(and=assocs['and'])
View(df)
?data.frame
for el in names(assocs){
if (df ==NULL){
df[el]<-assocs[el]
df<-data.frame(assocs[el])
}else {
}
}
for el in names(assocs){
range(names(assocs))
range(length(names(assocs)))
range(1,length(names(assocs)))
seq(1,length(names(assocs)))
for i in seq(1,length(names(assocs)){
for (i in seq(1,length(names(assocs))){
for (i in seq(1,length(names(assocs))){
el<-names(assocs)[i]
if (df ==NULL){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
for (i in seq(1,length(names(assocs)))){
el<-names(assocs)[i]
if (df ==NULL){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
df<-NULL
for (i in seq(1,length(names(assocs)))){
el<-names(assocs)[i]
if (df ==NULL){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
df<-NULL
for (i in seq(1,length(names(assocs)))){
el<-names(assocs)[i]
if (!df){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
df<-NULL
for (i in seq(1,length(names(assocs)))){
el<-names(assocs)[i]
if (df == NULL){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
df==NULL
is.na(df)
is.null(df)
df<-NULL
for (i in seq(1,length(names(assocs)))){
el<-names(assocs)[i]
if (is.null(df)){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
names(assocs)
View(df)
length(assocs["after"])
length(assocs["about"])
assocs["about"]
df["about"]<-assocs["about"]
View(df)
df["after"]<-assocs["after"]
length(assocs["after"])
typeof(assocs["after"])
typeof(assocs["after"][1])
typeof(assocs["after"][[1]])
length(assocs["after"][[1]])
ocs(tdt
assocs<-findAssocs(tdtdmFreqm, tdmFreq$dimnames$Terms, 0)
assocs<-findAssocs(tdtdmFreqm, tdmFreq$dimnames$Terms, 0)
assocs<-findAssocs(tdmFreq, tdmFreq$dimnames$Terms, 0)
df<-NULL
for (i in seq(1,length(names(assocs)))){
el<-names(assocs)[i]
if (is.null(df)){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
inspect(tdmFreq)
?findAssocs
findAssocs(tdmFreq, "and", 0)
length(tdmFreq$dimnames$Terms)
df<-NULL
for (i in seq(1,length(tdmFreq$dimnames$Terms))){
el<-tdmFreq$dimnames$Terms[i]
assocs<-findAssocs(tdmFreq, el, 0)
if (is.null(df)){
df<-data.frame(assocs[el])
}else {
df[el]<-assocs[el]
}
}
View(df)
findAssocs(tdmFreq, "and", -1)
findAssocs(tdmFreq, "and")
findAssocs(tdmFreq, "and",0.0)
length(assocs["and"])
length(assocs["and"][[1]])
length(assocs["after"][[1]])
a<-c(1,2,3)
names(a)<-c("one","tow", "three")
a
b<-c(1,2,3)
names(b)<-c("one", "four", "three")
a+b
b+a
names(assocs["after"])
names(assocs["after"][[1]])
tdmFreq$dimnames$Terms
terms <- tdmFreq$dimnames$Terms
for (term in terms){
term
}
?c
res<-c(1:length(terms))
names(res)<-terms
res<-0
?zero
res<-rep(0, length(terms))
names(res)<-terms
res[1]
res["about"]
assocs[el]
assocs[el, "they"]
assocs[el]["they"]
assocs[el][[1]]["they"]
?list
a<-list(x=c(0,1))
a
names(a)
names(a)<-c("rr")
names(a)
a
res<-rep(0, length(terms))
names(res)<-terms
l<-list(x<-res)
names(l)<-el
l
l[el]
l[[el]]
df<-NULL
terms <- tdmFreq$dimnames$Terms
for (el in terms){
assocs<-findAssocs(tdmFreq, el, 0)
res<-rep(0, length(terms))
names(res)<-terms
l<-list(x<-res)
names(l)<-el
for (term in terms){
values<-assocs[[el]]
if (term %in% names(values)){
l[[el]][term]<-values[term]
}
}
if (is.null(df)){
df<-data.frame(l)
}else {
df[el]<-l
}
}
View(df)
mat<-as.matrix(df)
library(reshape2)
mat <- melt(mat, value.name = "count")
View(mat)
ggplot(mat, aes(x = Var1, y = Var2, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("")
